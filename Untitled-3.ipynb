{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.3)\n",
    "data=pd.read_csv(\"abalone.csv\")\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.describe()\n",
    "\n",
    "cols = 3\n",
    "rows = 3\n",
    "num_cols = data.select_dtypes(exclude='object').columns\n",
    "fig = plt.figure( figsize=(cols*5, rows*5))\n",
    "for i, col in enumerate(num_cols):\n",
    "   \n",
    "    ax=fig.add_subplot(rows,cols,i+1)\n",
    "   \n",
    "    sns.histplot(x = data[col], ax = ax)\n",
    "   \n",
    "fig.tight_layout()  \n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#create scatterplot of hours vs. score\n",
    "plt.scatter(data.Height, data.Diameter)\n",
    "plt.title('Height vs Diameter')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Diameter')\n",
    "\n",
    "sns.pairplot(data);\n",
    "\n",
    "data.mean()\n",
    "\n",
    "data.median()  \n",
    "\n",
    "norm_data = pd.DataFrame(np.random.normal(size=100000))\n",
    "\n",
    "norm_data.plot(kind=\"density\",\n",
    "              figsize=(10,10));\n",
    "\n",
    "\n",
    "plt.vlines(norm_data.mean(),     # Plot black line at mean\n",
    "           ymin=0,\n",
    "           ymax=0.4,\n",
    "           linewidth=5.0);\n",
    "\n",
    "plt.vlines(norm_data.median(),   # Plot red line at median\n",
    "           ymin=0,\n",
    "           ymax=0.4,\n",
    "           linewidth=2.0,\n",
    "           color=\"red\");\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.isnull()\n",
    "\n",
    "df.fillna(method ='pad')\n",
    "\n",
    "print(df['Shell weight'].skew())\n",
    "df['Shell weight'].describe()\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "categorical_columns\n",
    "\n",
    "data_categorical = data[categorical_columns]\n",
    "data_categorical.head()\n",
    "\n",
    "from sklearn import preprocessing\n",
    " \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'species'.\n",
    "df['Sex']= label_encoder.fit_transform(df['Sex'])\n",
    "df['Sex'].unique() \n",
    "\n",
    "\n",
    "X= data.iloc[ : , :-1].values\n",
    "\n",
    "y= data.iloc[ : , 4].values\n",
    "print(X,y)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing data\n",
    "print(df.shape)\n",
    "\n",
    "# head of the data\n",
    "print('Head of the dataframe : ')\n",
    "print(df.head())\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "X= df['Whole weight']\n",
    "y=df['Shucked weight']\n",
    "\n",
    "# using the train test split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X,y , random_state=104,test_size=0.25, shuffle=True)\n",
    "\n",
    "# printing out train and test sets\n",
    "\n",
    "print('X_train : ')\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "\n",
    "print('')\n",
    "print('X_test : ')\n",
    "print(X_test.head())\n",
    "print(X_test.shape)\n",
    "\n",
    "print('')\n",
    "print('y_train : ')\n",
    "print(y_train.head())\n",
    "print(y_train.shape)\n",
    "\n",
    "print('')\n",
    "print('y_test : ')\n",
    "print(y_test.head())\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "df_scaled = df.copy()\n",
    "col_names = ['Shucked weight', 'Whole weight']\n",
    "features = df_scaled[col_names]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(5, 10))\n",
    "\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "df_scaled\n",
    "\n",
    "\n",
    "#testing and training\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    " \n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.05, random_state=0)\n",
    "print(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg= LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred=logreg.predict(X_test)\n",
    "print (X_test) #test dataset\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "\n",
    "X_train\n",
    "\n",
    "\n",
    "\n",
    "y_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "X_actual = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "Y_predic = [1, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n",
    "results = confusion_matrix(X_actual, Y_predic)\n",
    "print ('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score is',accuracy_score(X_actual, Y_predic))\n",
    "print ('Classification Report : ')\n",
    "print (classification_report(X_actual, Y_predic))\n",
    "print('AUC-ROC:',roc_auc_score(X_actual, Y_predic))\n",
    "print('LOGLOSS Value is',log_loss(X_actual, Y_predic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
